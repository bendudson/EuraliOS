* TCP stack

Now that we have a basic network card driver we can use the [[https://docs.rs/smoltcp/latest/smoltcp/][smoltcp]]
crate to add a network stack.

#+begin_src bash
  cargo new tcp
#+end_src

** Communication conflicts

To get started with a TCP stack, I tried opening a connection
to the PCI server and sending a character message:
#+begin_src rust
  #[no_mangle]
  fn main() {
      debug_println!("[tcp] Starting");

      let handle = syscalls::open("/pci").expect("Couldn't open pci");
      syscalls::send(&handle,
                     syscalls::Message::Short(
                         syscalls::MESSAGE_TYPE_CHAR,
                         'X' as u64, 0));
  }
#+end_src

This results in =rtl8139= panicking, shown in figure [[fig-panic]].

#+CAPTION: Both =rtl8139= and =tcp= programs try to send messages to =pci=.
#+NAME: fig-panic
[[./img/15-01-panic.png]]

What has happened is that =tcp= has sent a message before =pci= has
called =receive=, so the rendezvous is put into the =Sending=
state. Before =pci= receives this message, =rtl8139= calls =rcall=
(line 24), receiving =SyscallError(1)=
i.e. =SYSCALL_ERROR_SEND_BLOCKING=.

This is going to happen increasingly often as we add more programs,
and multiple device drivers which all try to access the same
resources.  We need to make =rcall= more robust so that these
conflicts don't crash our program.

For =Short= messages, which just contain =u64= values, the solution is
quite simple: We can just wait for a bit, perhaps yielding to let
other threads to run which will hopefully unblock the rendezvous,
and try sending another message.

=Long= messages are more complicated because they transfer
communication and memory resources between processes. If a message is
sent but an error returned, then those resources are lost, potentially
leaked. I think the options are:
1. Long messages remove resources from the sending process (as now),
   then if an error occurs the resources are returned to the original
   thread. The sender gets back an error code along with their
   message, though the handle internals may be different. The sender
   can then choose whether to try again.
2. A variation is to copy resources from the sender, and only remove them
   from the sender when the message is sent or stored in the Rendezvous.
   In this case the Message passed into the =send()= function would remain
   valid, and could be sent again. =Message::from_values= already does this
   two-stage process (copy, then remove) to handle errors in constructing
   the Message.
3. A more complex solution would be to add a queue of senders to =Rendezvous=,
   so sending to a blocked Rendezvous would put the sending thread into
   a queue, suspended until the message could be received.

There may be other ways that messages could fail to be delivered,
requiring messages to be returned to their sender, so (1) or (2) will
be needed. (3) seems like an optimisation which could be added later.

** Aside: A thread_yield system call

In a few places now we need to wait for a while to allow state to
change, or messages to be received. Rather than using CPU cycles in a
big =nop= loop, we can instead yield the processor, allowing other
more useful threads to run.  One of them may indeed need to run before
the current thread can do anything.

Fortunately adding a =thread_yield= system call is quite straightforward
using the pieces we already have. In the kernel (=syscalls.rs=) we just schedule
the next thread and launch it (via =iret=):
#+begin_src rust
  fn sys_yield(context_ptr: *mut Context) {
      let next_stack = process::schedule_next(context_ptr as usize);
      interrupts::launch_thread(next_stack);
  }
#+end_src
In the user library =euralios_std= the function just calls with
=SYSCALL_YIELD= in =rax= (value 9 currently):
#+begin_src rust
  pub fn thread_yield() {
      unsafe{
          asm!("syscall",
               in("rax") SYSCALL_YIELD,
               out("rcx") _,
               out("r11") _);
      }
  }
#+end_src

Everywhere we need to wait, such as in =rcall= if the rendezvous is
blocked, we can now call =syscalls::thread_yield()=.
